{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c15aca9",
   "metadata": {},
   "source": [
    "# Running Multilingual Character-Level LSTM in Google Colab\n",
    "\n",
    "This notebook guides you through running the character-level LSTM model in Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497becff",
   "metadata": {},
   "source": [
    "## Step 1: Check GPU Availability\n",
    "\n",
    "First, verify that Colab has assigned a GPU to your notebook. Go to **Runtime > Change runtime type** and select **GPU** as your hardware accelerator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7181e9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "import torch\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a8bbd2",
   "metadata": {},
   "source": [
    "## Step 2: Clone the Project Repository\n",
    "\n",
    "Option 1: Clone your GitHub repository (if you've pushed the code to GitHub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ed6682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your actual repository URL\n",
    "!git clone https://github.com/yourusername/cse517p-project.git\n",
    "%cd cse517p-project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3514351",
   "metadata": {},
   "source": [
    "Option 2: Upload files manually\n",
    "\n",
    "If you haven't pushed to GitHub, you'll need to create the project structure and upload the necessary files. Run the following cell and then upload the required files through the Colab file browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690f2da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create project directory structure\n",
    "!mkdir -p cse517p-project/src cse517p-project/data cse517p-project/work cse517p-project/example\n",
    "%cd cse517p-project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395b2e95",
   "metadata": {},
   "source": [
    "## Step 3: Install Required Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ea2ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install numpy tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24617e77",
   "metadata": {},
   "source": [
    "## Step 4: Download Multilingual Training Data\n",
    "\n",
    "Let's download sample multilingual data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58c7a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download sample data\n",
    "!mkdir -p data\n",
    "\n",
    "# English sample (Pride and Prejudice)\n",
    "!curl -s https://www.gutenberg.org/files/1342/1342-0.txt > data/english_pride_prejudice.txt\n",
    "\n",
    "# Spanish sample (Don Quixote)\n",
    "!curl -s https://www.gutenberg.org/files/2000/2000-0.txt > data/spanish_don_quijote.txt\n",
    "\n",
    "# Additional multilingual samples can be added here\n",
    "# French sample (Les Misérables - Tome I)\n",
    "!curl -s https://www.gutenberg.org/files/17489/17489-0.txt > data/french_les_miserables.txt\n",
    "\n",
    "# German sample (Also sprach Zarathustra)\n",
    "!curl -s https://www.gutenberg.org/cache/epub/1998/pg1998.txt > data/german_zarathustra.txt\n",
    "\n",
    "# Italian sample (La Divina Commedia di Dante)\n",
    "!curl -s https://www.gutenberg.org/files/1001/1001-0.txt > data/italian_divina_commedia.txt\n",
    "\n",
    "# Portuguese sample (Os Lusíadas)\n",
    "!curl -s https://www.gutenberg.org/files/3333/3333-0.txt > data/portuguese_lusiadas.txt\n",
    "\n",
    "# Dutch sample (Max Havelaar)\n",
    "!curl -s https://www.gutenberg.org/files/36000/36000-0.txt > data/dutch_max_havelaar.txt\n",
    "\n",
    "# Swedish sample (Röda rummet)\n",
    "!curl -s https://www.gutenberg.org/files/5381/5381-0.txt > data/swedish_roda_rummet.txt\n",
    "\n",
    "# Finnish sample (Seitsemän veljestä)\n",
    "!curl -s https://www.gutenberg.org/files/11961/11961-0.txt > data/finnish_seitseman_veljesta.txt\n",
    "\n",
    "# Danish sample (Niels Lyhne)\n",
    "!curl -s https://www.gutenberg.org/files/19099/19099-0.txt > data/danish_niels_lyhne.txt\n",
    "\n",
    "# Norwegian sample (Peer Gynt)\n",
    "!curl -s https://www.gutenberg.org/files/2339/2339-0.txt > data/norwegian_peer_gynt.txt\n",
    "\n",
    "# Polish sample (Pan Tadeusz)\n",
    "!curl -s https://www.gutenberg.org/files/20933/20933-0.txt > data/polish_pan_tadeusz.txt\n",
    "\n",
    "# Hungarian sample (Az arany ember)\n",
    "!curl -s https://www.gutenberg.org/files/20925/20925-0.txt > data/hungarian_az_arany_ember.txt\n",
    "\n",
    "# Latin sample (Commentarii de Bello Gallico)\n",
    "!curl -s https://www.gutenberg.org/files/10657/10657-0.txt > data/latin_bello_gallico.txt\n",
    "\n",
    "# Russian sample (War and Peace)\n",
    "!curl -s https://www.gutenberg.org/files/2600/2600-0.txt > data/russian_war_and_peace.txt\n",
    "\n",
    "# Chinese sample (The Art of War)\n",
    "!curl -s https://www.gutenberg.org/files/132/132-0.txt > data/chinese_art_of_war.txt\n",
    "# Japanese sample (The Tale of Genji)\n",
    "!curl -s https://www.gutenberg.org/files/23643/23643-0.txt > data/japanese_genji_monogatari.txt\n",
    "# Korean sample (The Tale of Hong Gildong)  \n",
    "!curl -s https://www.gutenberg.org/files/22060/22060-0.txt > data/korean_hong_gildong.txt\n",
    "# Arabic sample (One Thousand and One Nights)\n",
    "!curl -s https://www.gutenberg.org/files/555/555-0.txt > data/arabic_one_thousand_and_one_nights.txt\n",
    "# Hindi sample (The Ramayana)\n",
    "!curl -s https://www.gutenberg.org/files/24899/24899-0.txt > data/hindi_ramayana.txt\n",
    "\n",
    "\n",
    "# Create example input file for testing\n",
    "!mkdir -p example\n",
    "!echo \"Hello, how are you\" > example/input.txt\n",
    "!echo \"Bonjour mon ami\" >> example/input.txt\n",
    "!echo \"Hola, ¿cómo estás\" >> example/input.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c35142",
   "metadata": {},
   "source": [
    "## Step 5: If needed, create or upload the Python files\n",
    "\n",
    "If you cloned from GitHub, skip this step. Otherwise, you need to upload or create your Python files in the `src` directory.\n",
    "\n",
    "Click on the folder icon on the left sidebar, navigate to the `src` directory, and upload your `myprogram.py` and `predict.sh` files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb4455c",
   "metadata": {},
   "source": [
    "## Step 6: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4206d3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "!python src/myprogram.py train --work_dir work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180bba38",
   "metadata": {},
   "source": [
    "## Step 7: Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de478e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "!mkdir -p output\n",
    "\n",
    "# Run prediction\n",
    "!python src/myprogram.py test --work_dir work --test_data example/input.txt --test_output output/pred.txt\n",
    "\n",
    "# Display predictions\n",
    "print(\"Input text:\")\n",
    "!cat example/input.txt\n",
    "\n",
    "print(\"\\nPredictions (top 3 next characters):\")\n",
    "!cat output/pred.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd13f5d1",
   "metadata": {},
   "source": [
    "## Step 8: Save the Trained Model\n",
    "\n",
    "If you want to save your trained model from Colab to your local machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6cc5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip the work directory which contains your model\n",
    "!zip -r trained_model.zip work/\n",
    "\n",
    "# Download the model (click the link that appears)\n",
    "from google.colab import files\n",
    "files.download('trained_model.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8531649",
   "metadata": {},
   "source": [
    "## Optional: Experiment with Hyperparameters\n",
    "\n",
    "You can modify the training hyperparameters by editing the code or passing additional arguments. Here's an example of how to modify key parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8affed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary modified version of the program with different hyperparameters\n",
    "%%writefile src/modified_program.py\n",
    "# Import the original program\n",
    "from src.myprogram import *\n",
    "\n",
    "# Override the run_train method to use different hyperparameters\n",
    "def custom_run_train(self, data, work_dir):\n",
    "    # Create dataset with smaller sequence length\n",
    "    seq_length = 32  # Smaller sequence length\n",
    "    self.dataset = CharDataset(data, seq_length)\n",
    "    \n",
    "    # Create model with different parameters\n",
    "    vocab_size = self.dataset.vocab_size\n",
    "    embedding_dim = 64     # Smaller embedding size\n",
    "    hidden_dim = 128       # Smaller hidden dimension\n",
    "    num_layers = 1         # Fewer layers\n",
    "    self.model = CharLSTM(vocab_size, embedding_dim, hidden_dim, num_layers)\n",
    "    self.model.to(self.device)\n",
    "    \n",
    "    # Modified training parameters\n",
    "    batch_size = 32        # Smaller batch size\n",
    "    num_epochs = 5         # Fewer epochs\n",
    "    learning_rate = 0.005  # Higher learning rate\n",
    "    \n",
    "    # Create DataLoader\n",
    "    dataloader = DataLoader(self.dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for batch_idx, (sequences, labels) in enumerate(dataloader):\n",
    "            sequences, labels = sequences.to(self.device), labels.to(self.device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = self.model(sequences)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f'Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}, Loss: {loss.item():.4f}')\n",
    "        \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}')\n",
    "\n",
    "# Apply the monkey patch\n",
    "MyModel.run_train = custom_run_train\n",
    "\n",
    "# Run with the modified script\n",
    "if __name__ == '__main__':\n",
    "    # Use the same main code from the original program\n",
    "    from src.myprogram import *\n",
    "    if __name__ == '__main__' and globals()['__name__'] == '__main__':\n",
    "        parser = ArgumentParser(formatter_class=ArgumentDefaultsHelpFormatter)\n",
    "        parser.add_argument('mode', choices=('train', 'test'), help='what to run')\n",
    "        parser.add_argument('--work_dir', help='where to save', default='work_modified')\n",
    "        parser.add_argument('--test_data', help='path to test data', default='example/input.txt')\n",
    "        parser.add_argument('--test_output', help='path to write test predictions', default='pred_modified.txt')\n",
    "        args = parser.parse_args()\n",
    "\n",
    "        random.seed(0)\n",
    "\n",
    "        if args.mode == 'train':\n",
    "            if not os.path.isdir(args.work_dir):\n",
    "                print('Making working directory {}'.format(args.work_dir))\n",
    "                os.makedirs(args.work_dir)\n",
    "            print('Instatiating model')\n",
    "            model = MyModel()\n",
    "            print('Loading training data')\n",
    "            train_data = MyModel.load_training_data()\n",
    "            print('Training')\n",
    "            model.run_train(train_data, args.work_dir)\n",
    "            print('Saving model')\n",
    "            model.save(args.work_dir)\n",
    "        elif args.mode == 'test':\n",
    "            print('Loading model')\n",
    "            model = MyModel.load(args.work_dir)\n",
    "            print('Loading test data from {}'.format(args.test_data))\n",
    "            test_data = MyModel.load_test_data(args.test_data)\n",
    "            print('Making predictions')\n",
    "            pred = model.run_pred(test_data)\n",
    "            print('Writing predictions to {}'.format(args.test_output))\n",
    "            assert len(pred) == len(test_data), 'Expected {} predictions but got {}'.format(len(test_data), len(pred))\n",
    "            model.write_pred(pred, args.test_output)\n",
    "        else:\n",
    "            raise NotImplementedError('Unknown mode {}'.format(args.mode))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56103999",
   "metadata": {},
   "source": [
    "Run the modified version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507afc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with modified hyperparameters\n",
    "!python src/modified_program.py train --work_dir work_modified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b01e81",
   "metadata": {},
   "source": [
    "## Running with Docker in Google Colab\n",
    "\n",
    "You can also run your model using Docker inside Google Colab, which ensures the exact same environment as your local setup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040bb818",
   "metadata": {},
   "source": [
    "### 1. Install Docker in Colab\n",
    "\n",
    "First, we need to install Docker in the Colab environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5707fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any old Docker installations\n",
    "!apt-get remove docker docker-engine docker.io containerd runc\n",
    "\n",
    "# Install prerequisites\n",
    "!apt-get update\n",
    "!apt-get install -y apt-transport-https ca-certificates curl gnupg lsb-release\n",
    "\n",
    "# Add Docker's official GPG key\n",
    "!curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg\n",
    "\n",
    "# Set up the stable repository\n",
    "!echo \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" | tee /etc/apt/sources.list.d/docker.list > /dev/null\n",
    "\n",
    "# Install Docker Engine\n",
    "!apt-get update\n",
    "!apt-get install -y docker-ce docker-ce-cli containerd.io\n",
    "\n",
    "# Verify Docker installation\n",
    "!docker --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86fcb31",
   "metadata": {},
   "source": [
    "### 2. Start Docker service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e64727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the Docker service\n",
    "!service docker start\n",
    "\n",
    "# Check Docker status\n",
    "!service docker status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58484bfd",
   "metadata": {},
   "source": [
    "### 3. Create Project Files for Docker\n",
    "\n",
    "We need to create all necessary files for our Docker container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857be0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dockerfile\n",
    "%%writefile Dockerfile\n",
    "# Using the latest PyTorch image with CUDA support\n",
    "FROM pytorch/pytorch:2.6.0-cuda12.4-cudnn9-runtime\n",
    "\n",
    "RUN mkdir /job\n",
    "WORKDIR /job\n",
    "VOLUME [\"/job/data\", \"/job/src\", \"/job/work\", \"/job/output\"]\n",
    "\n",
    "# Install dependencies using requirements.txt\n",
    "COPY requirements.txt /job/\n",
    "RUN pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc311a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create requirements.txt\n",
    "%%writefile requirements.txt\n",
    "numpy>=1.20.0\n",
    "tqdm>=4.64.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42d6309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predict.sh script\n",
    "%%writefile src/predict.sh\n",
    "#!/usr/bin/env bash\n",
    "set -e\n",
    "set -v\n",
    "python src/myprogram.py test --work_dir work --test_data $1 --test_output $2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a78f09",
   "metadata": {},
   "source": [
    "### 4. Build Docker Image\n",
    "\n",
    "Now we can build the Docker image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27269661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Docker image\n",
    "!docker build -t cse517-proj/mylstm -f Dockerfile ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66c5e1c",
   "metadata": {},
   "source": [
    "### 5. Run Training with Docker\n",
    "\n",
    "Now we can train our model using Docker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11f762f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure directories exist\n",
    "!mkdir -p data work output example\n",
    "\n",
    "# Check if chmod is needed for the script\n",
    "!chmod +x src/predict.sh\n",
    "\n",
    "# Run training with Docker\n",
    "!docker run --rm -v \"$PWD/src\":/job/src -v \"$PWD/data\":/job/data -v \"$PWD/work\":/job/work cse517-proj/mylstm bash -c \"cd /job && python src/myprogram.py train --work_dir work\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa51a9c",
   "metadata": {},
   "source": [
    "### 6. Run Testing with Docker\n",
    "\n",
    "Now we can test our model using Docker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aa5128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test data if it doesn't exist\n",
    "!mkdir -p example\n",
    "!echo \"Hello, how are you\" > example/input.txt\n",
    "!echo \"Bonjour mon ami\" >> example/input.txt\n",
    "!echo \"Hola, ¿cómo estás\" >> example/input.txt\n",
    "\n",
    "# Run testing with Docker\n",
    "!docker run --rm -v \"$PWD/src\":/job/src -v \"$PWD/work\":/job/work -v \"$PWD/example\":/job/data -v \"$PWD/output\":/job/output cse517-proj/mylstm bash /job/src/predict.sh /job/data/input.txt /job/output/pred.txt\n",
    "\n",
    "# Display results\n",
    "print(\"Input:\")\n",
    "!cat example/input.txt\n",
    "print(\"\\nPredictions:\")\n",
    "!cat output/pred.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac9cd60",
   "metadata": {},
   "source": [
    "### 7. Compare Docker vs. Direct Execution\n",
    "\n",
    "You can now compare the results between running directly in Colab versus running in Docker. Both should produce similar results, but Docker ensures better reproducibility and consistency with your local environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8881999f",
   "metadata": {},
   "source": [
    "### Notes on Running Docker in Colab\n",
    "\n",
    "1. Docker in Colab requires administrative privileges, which Google provides.\n",
    "2. The Docker installation process might take a few minutes.\n",
    "3. If you encounter memory issues, try reducing batch sizes or sequence lengths.\n",
    "4. Docker containers are ephemeral - data will be lost when the container stops unless mounted as volumes.\n",
    "5. Colab sessions have time limits - save your model frequently."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
